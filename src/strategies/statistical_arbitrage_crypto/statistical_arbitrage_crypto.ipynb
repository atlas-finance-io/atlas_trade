{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Arbitrage Crypto\n",
    "\n",
    "Some calculations to do with statistical arbitrage on binance using perpetual futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import coint\n",
    "import statsmodels.api as sm\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import ccxt\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step One (Correlation)\n",
    "\n",
    "We will gather a universe of possible USDT perpetual trading pairs that are available on binance. We want to filter out pairs that aren't correlated together before we can do our co-integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures_pairs =  [\n",
    "    \"BTCUSDT\", \"ETHUSDT\", \"LINKUSDT\", \"BNBUSDT\", \"TRXUSDT\", \"DOTUSDT\", \"ADAUSDT\", \"EOSUSDT\", \"LTCUSDT\",\n",
    "    \"BCHUSDT\", \"XRPUSDT\", \"ETCUSDT\", \"FILUSDT\", \"EGLDUSDT\", \"DOGEUSDT\", \"UNIUSDT\", \"THETAUSDT\", \"XLMUSDT\",\n",
    "    \"SOLUSDT\", \"FTMUSDT\", \"SANDUSDT\", \"MANAUSDT\", \"AVAXUSDT\", \"GALAUSDT\", \"MATICUSDT\", \"NEARUSDT\",\n",
    "    \"ATOMUSDT\", \"AAVEUSDT\", \"AXSUSDT\", \"ROSEUSDT\", \"XTZUSDT\", \"ICXUSDT\", \"ALGOUSDT\", \"RUNEUSDT\",\n",
    "    \"APEUSDT\", \"VETUSDT\", \"ZILUSDT\", \"KNCUSDT\", \"XMRUSDT\", \"GMTUSDT\", \"OPUSDT\", \"ENSUSDT\", \"CHZUSDT\", \"APTUSDT\"\n",
    "]\n",
    "\n",
    "# futures_pairs =  [\n",
    "#     \"BTCUSDT\", \"ETHUSDT\"\n",
    "# ]\n",
    "\n",
    "\n",
    "def fetch_historical_data(pair,  since, timeframe = \"1h\"):\n",
    "    binance = ccxt.binance({'rateLimit': 1200}) # Binance rate limit is 1200 ms\n",
    "    all_candles = []\n",
    "    limit = 1000  # Max number of candles per request\n",
    "    while since < binance.milliseconds():\n",
    "        candles = binance.fetch_ohlcv(pair, timeframe, since, limit)\n",
    "        if len(candles) == 0:\n",
    "            break\n",
    "        since = candles[-1][0] + 1  # start the next call right where the last one ended\n",
    "        all_candles += candles\n",
    "        time.sleep(binance.rateLimit / 1000)  # sleep for rateLimit milliseconds\n",
    "    \n",
    "    df = pd.DataFrame(all_candles, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    return df['close']\n",
    "\n",
    "\n",
    "\n",
    "def visualize_heatmap(correlation_matrix):\n",
    "\n",
    "    plt.style.use(\"dark_background\")\n",
    "\n",
    "    # Creating a custom colormap: Green for positive, Red for negative correlation\n",
    "    custom_cmap = sns.diverging_palette(10, 130, s=80, l=55, as_cmap=True)  # Using green-red palette\n",
    "\n",
    "    plt.figure(figsize=(25, 25))  # Increased size\n",
    "\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap=custom_cmap, \n",
    "                center=0, vmin=-1, vmax=1, fmt=\".2f\", \n",
    "                linewidths=.5, cbar_kws={\"shrink\": 0.75},\n",
    "                annot_kws={\"size\": 10, \"color\": \"white\"})  # Setting the font color to white for visibility on dark background\n",
    "\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.title(\"Correlation Matrix Heatmap\", fontsize=20)  # Increased font size for the title\n",
    "    plt.tight_layout()\n",
    "    plt.show() \n",
    "\n",
    "binance = ccxt.binance()\n",
    "\n",
    "# Define a time span: 2 months in milliseconds\n",
    "two_months_ms = 2 * 30 * 24 * 60 * 60 * 1000\n",
    "since = binance.milliseconds() - two_months_ms\n",
    "\n",
    "dataframes = {}\n",
    "for pair in futures_pairs:\n",
    "    print(f\"Fetching data for {pair}...\")\n",
    "    dataframes[pair] = fetch_historical_data(pair, since)\n",
    "\n",
    "# Combining all pairs' close prices into one dataframe\n",
    "combined_df = pd.concat(dataframes, axis=1)\n",
    "\n",
    "# Calculating correlation matrix\n",
    "correlation_matrix = combined_df.corr()\n",
    "\n",
    "visualize_heatmap(correlation_matrix)\n",
    "\n",
    "high_correlation_pairs = []\n",
    "\n",
    "# Iterate over the upper triangular matrix to avoid duplicate pairs and self-correlation\n",
    "for i, crypto1 in enumerate(correlation_matrix.columns):\n",
    "    for j, crypto2 in enumerate(correlation_matrix.columns):\n",
    "        if i < j and correlation_matrix.loc[crypto1, crypto2] > 0.75:\n",
    "            high_correlation_pairs.append((crypto1, crypto2, correlation_matrix.loc[crypto1, crypto2]))\n",
    "\n",
    "# print(high_correlation_pairs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 (Cointegration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "suitable_pairs = []\n",
    "\n",
    "\n",
    "for pair1, pair2, correlation in high_correlation_pairs:\n",
    "    ohlcv1 = fetch_historical_data(pair1, since, '1h')\n",
    "    ohlcv2 = fetch_historical_data(pair2, since, '1h')\n",
    "    \n",
    "    df1 = pd.DataFrame(ohlcv1, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df2 = pd.DataFrame(ohlcv2, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "\n",
    "    min_length = min(len(df1), len(df2))\n",
    "    df1 = df1.iloc[-min_length:]\n",
    "    df2 = df2.iloc[-min_length:]\n",
    "\n",
    "    _, pvalue, _ = coint(df1['close'], df2['close'])\n",
    "    \n",
    "    if pvalue < 0.05:  # Check for cointegration \n",
    "        suitable_pairs.append((pair1, pair2))\n",
    "\n",
    "print(suitable_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreads = {}\n",
    "\n",
    "# Calculate the spread for each pair\n",
    "for pair in suitable_pairs:\n",
    "    asset_A_prices = fetch_historical_data(pair[0], since, '1h')\n",
    "    asset_B_prices = fetch_historical_data(pair[1], since, '1h')\n",
    "    \n",
    "    # Compute the hedge ratio using linear regression\n",
    "    asset_A_prices_const = sm.add_constant(asset_A_prices)\n",
    "    model = sm.OLS(asset_B_prices, asset_A_prices_const).fit()\n",
    "    hedge_ratio = model.params[1]\n",
    "    \n",
    "    # Calculate the spread\n",
    "    spread = np.array(asset_A_prices) - hedge_ratio * np.array(asset_B_prices)\n",
    "    spreads[pair] = spread\n",
    "\n",
    "print(spreads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spread Analysis\n",
    "\n",
    "Now we must analyze the spread for mean-reverting properties using the z score.  The z-score is a measure of how many standard deviations a data point is away from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# A dictionary to store z-scores for each pair\n",
    "z_scores = {}\n",
    "\n",
    "# Calculate the z-scores for each spread\n",
    "for pair, spread in spreads.items():\n",
    "    mean_spread = np.mean(spread)\n",
    "    std_spread = np.std(spread)\n",
    "    z = (spread - mean_spread) / std_spread\n",
    "    z_scores[pair] = z\n",
    "\n",
    "mean_reverting_pairs = []\n",
    "\n",
    "# Test each z-score series for mean reversion\n",
    "for pair, z in z_scores.items():\n",
    "    result = adfuller(z)\n",
    "    adf_statistic = result[0]\n",
    "    p_value = result[1]\n",
    "    \n",
    "    # Let's consider a p-value threshold of 0.05, for instance\n",
    "    if p_value < 0.05:\n",
    "        mean_reverting_pairs.append(pair)\n",
    "        print(f\"{pair} is likely mean-reverting with p-value: {p_value:.4f}\")\n",
    "        \n",
    "        # Optional: Plotting the z-score for the mean-reverting pair\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(z, label=f'Z-Score of {pair}')\n",
    "        plt.axhline(0, color='gray', linestyle='--')\n",
    "        plt.axhline(2.0, color='red', linestyle='--', label='Upper Threshold')\n",
    "        plt.axhline(-2.0, color='green', linestyle='--', label='Lower Threshold')\n",
    "        plt.legend()\n",
    "        plt.title(f'Z-Score for {pair}')\n",
    "        plt.show()\n",
    "\n",
    "print(\"Mean-reverting pairs:\", mean_reverting_pairs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
